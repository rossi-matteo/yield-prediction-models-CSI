{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCC - Univariate Linear Regression Model\n",
    "\n",
    "**Scores**\n",
    "* RMSE [2021-2050]: 1.414\n",
    "* RMSE [2051-2098]: 3.072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-09T08:59:18.839608Z",
     "iopub.status.busy": "2024-12-09T08:59:18.839186Z",
     "iopub.status.idle": "2024-12-09T08:59:20.010846Z",
     "shell.execute_reply": "2024-12-09T08:59:20.009331Z",
     "shell.execute_reply.started": "2024-12-09T08:59:18.839574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import matplotlib.pylab as plt\n",
    "import gc\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname,_, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "        break\n",
    "\n",
    "import tqdm\n",
    "import datetime\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T08:59:21.737721Z",
     "iopub.status.busy": "2024-12-09T08:59:21.736882Z",
     "iopub.status.idle": "2024-12-09T08:59:21.744271Z",
     "shell.execute_reply": "2024-12-09T08:59:21.743227Z",
     "shell.execute_reply.started": "2024-12-09T08:59:21.737681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DEBUG_MODE = False\n",
    "\n",
    "CROPS = (\"maize\", \"wheat\")\n",
    "\n",
    "MODES = ('train', 'test')\n",
    "\n",
    "FEATURES_TEMPORAL = {\n",
    "    # Time series data -- 240 columns reflecting daily values for 30 days before sowing and 210 days after.\n",
    "    'tas',       # Mean daily temperature\n",
    "    'tasmax',    # Max daily temperature\n",
    "    'tasmin',    # Min daily temperature\n",
    "    'pr',        # precipitation\n",
    "    'rsds'      # shortwave radiation\n",
    "}\n",
    "\n",
    "FEATURES_STATIC = {\n",
    "    # Static data\n",
    "    'soil_co2',  # crop, year, lon, lat, texture_class, real_year, co2, nitrogen\n",
    "    # dominant USDA soil texture class (constant over time), the ambient CO2 concentration (spatially constant), the planting date and the nitrogen application rate (constant over time)\n",
    "}\n",
    "\n",
    "#FEATURES = set.union(FEATURES_TEMPORAL, FEATURES_STATIC)\n",
    "FEATURES = FEATURES_STATIC\n",
    "\n",
    "COLUMNS_TO_DROP = ['crop','variable']\n",
    "\n",
    "# Sowing date\n",
    "INDEX_SOW = 30  # days\n",
    "# Time series data length\n",
    "SEASON_LENGTH = 240  # days\n",
    "# Nr. of soil texture classes\n",
    "NUM_TEXTURE_CLASSES = 13  \n",
    "\n",
    "YEAR_TRAIN_MIN = 1982\n",
    "YEAR_TRAIN_MAX = 2020  # Inclusive\n",
    "YEAR_TEST_MIN = 2021\n",
    "YEAR_TEST_MAX = 2098\n",
    "\n",
    "PATH_INPUT = os.path.abspath(os.path.join(os.sep, 'kaggle', 'input', 'the-future-crop-challenge'))\n",
    "# PATH_INPUT = os.path.abspath(os.path.join(os.getcwd(), 'data'))  # For running the notebook locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T08:59:23.432632Z",
     "iopub.status.busy": "2024-12-09T08:59:23.432239Z",
     "iopub.status.idle": "2024-12-09T08:59:23.443328Z",
     "shell.execute_reply": "2024-12-09T08:59:23.442195Z",
     "shell.execute_reply.started": "2024-12-09T08:59:23.432596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Reduce memory usage of a pandas DataFrame\n",
    "def reduce_memory_usage(df):\n",
    "    \"\"\"Reduce memory usage of a pandas DataFrame.\"\"\"\n",
    "    # Function to iterate through columns and modify the data types\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print(f\"Memory usage of dataframe: {start_mem} MB\")\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col in df.index.names:  # Skip index columns, since other formats of index aren't supported by the engine\n",
    "            continue\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)  # Keep sufficient precision\n",
    "            else:\n",
    "                if col == \"year\":  # Ensure precision for grouping columns\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print(f\"Memory usage after optimization: {end_mem} MB\")\n",
    "    #print(f\"Decreased by {100 * (start_mem - end_mem) / start_mem}%\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T08:59:31.812424Z",
     "iopub.status.busy": "2024-12-09T08:59:31.812049Z",
     "iopub.status.idle": "2024-12-09T08:59:31.821609Z",
     "shell.execute_reply": "2024-12-09T08:59:31.820462Z",
     "shell.execute_reply.started": "2024-12-09T08:59:31.812388Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(crop: str, # Which crop\n",
    "              mode: str, # Which dataset (i.e. train/test)\n",
    "              select_only_features: bool = True, # Drop every other column (crop, year, lon, lat) if not relevant for computation\n",
    "              take_subset: bool = False,  # If set to true, take a small subset of the data (for debugging purposes)\n",
    "             ) -> dict:\n",
    "    assert crop in CROPS\n",
    "    assert mode in MODES\n",
    "    \n",
    "    output = dict()\n",
    "    \n",
    "    for f in FEATURES:\n",
    "        path = os.path.join(PATH_INPUT, f'{f}_{crop}_{mode}.parquet')\n",
    "        df = reduce_memory_usage(pd.read_parquet(path))\n",
    "\n",
    "        columns_to_drop_in_df = [col for col in COLUMNS_TO_DROP if col in df.columns] \n",
    "        if columns_to_drop_in_df:\n",
    "            df = df.drop(columns=columns_to_drop_in_df)\n",
    "\n",
    "        if select_only_features:\n",
    "            if f in FEATURES_TEMPORAL:  # Select only the time series data -- drop other columns\n",
    "                df = df[[str(i) for i in range(SEASON_LENGTH)]]\n",
    "        \n",
    "        output[f] = df\n",
    "\n",
    "        # Free up memory after processing each file\n",
    "        del df  # Explicitly delete the DataFrame\n",
    "        gc.collect()  # Force garbage collection\n",
    "        \n",
    "    if mode == 'train':\n",
    "        output['target'] = pd.read_parquet(os.path.join(PATH_INPUT, f'{mode}_solutions_{crop}.parquet'))\n",
    "    \n",
    "    # If required, only take a subset of the data for debugging purposes -- we don't really care which samples\n",
    "    if take_subset:\n",
    "        num_select = 100  # Take only 100 samples from the dataset\n",
    "        # Select which samples based on the index of some feature\n",
    "        ixs_selected = output[tuple(FEATURES)[0]].index[:num_select]\n",
    "        # Filter all dataframes\n",
    "        output = {\n",
    "            key: df.loc[ixs_selected] for key, df in output.items()\n",
    "        }\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T08:59:34.132585Z",
     "iopub.status.busy": "2024-12-09T08:59:34.132193Z",
     "iopub.status.idle": "2024-12-09T08:59:35.133857Z",
     "shell.execute_reply": "2024-12-09T08:59:35.132797Z",
     "shell.execute_reply.started": "2024-12-09T08:59:34.132549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load all available data for all crops\n",
    "crop_data_train = {\n",
    "    crop: load_data(crop, 'train', take_subset=DEBUG_MODE, select_only_features=False) for crop in CROPS\n",
    "}\n",
    "\n",
    "\n",
    "crop_data_test = {\n",
    "    crop: load_data(crop, 'test', take_subset=DEBUG_MODE, select_only_features=False) for crop in CROPS\n",
    "}\n",
    "\n",
    "# Separate data in features and targets (if available)\n",
    "crop_features_train = {\n",
    "    crop: {\n",
    "        k: v for k, v in data.items() if k in FEATURES\n",
    "    } for crop, data in crop_data_train.items()\n",
    "}\n",
    "crop_features_test = {\n",
    "    crop: {\n",
    "        k: v for k, v in data.items() if k in FEATURES\n",
    "    } for crop, data in crop_data_test.items()\n",
    "}\n",
    "\n",
    "crop_targets_train = {\n",
    "    crop: data['target'] for crop, data in crop_data_train.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T10:00:27.908707Z",
     "iopub.status.busy": "2024-12-09T10:00:27.907550Z",
     "iopub.status.idle": "2024-12-09T10:00:27.917767Z",
     "shell.execute_reply": "2024-12-09T10:00:27.916553Z",
     "shell.execute_reply.started": "2024-12-09T10:00:27.908659Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        yield\n",
      "ID           \n",
      "0       5.595\n",
      "1       5.895\n",
      "2       3.023\n",
      "3       2.071\n",
      "4       2.239\n",
      "...       ...\n",
      "349714  6.240\n",
      "349715  8.926\n",
      "349716  2.180\n",
      "349717  7.311\n",
      "349718  2.118\n",
      "\n",
      "[349719 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "yield_maize_df = pd.DataFrame(crop_targets_train['maize'])\n",
    "yield_wheat_df = pd.DataFrame(crop_targets_train['wheat'])\n",
    "print(yield_maize_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T10:36:11.778808Z",
     "iopub.status.busy": "2024-12-09T10:36:11.778153Z",
     "iopub.status.idle": "2024-12-09T10:36:11.796680Z",
     "shell.execute_reply": "2024-12-09T10:36:11.795566Z",
     "shell.execute_reply.started": "2024-12-09T10:36:11.778769Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'soil_co2'}\n",
      "{'maize': {'soil_co2':           year     lon    lat  texture_class  real_year     co2    nitrogen\n",
      "ID                                                                         \n",
      "349719   420.0 -122.25  48.25            9.0       2021   418.0  186.125000\n",
      "349720   420.0 -122.25  48.75            9.0       2021   418.0  186.125000\n",
      "349721   420.0 -122.25  49.25            9.0       2021   418.0  184.875000\n",
      "349722   420.0 -119.75  47.75            9.0       2021   418.0  186.125000\n",
      "349723   420.0 -116.75  43.25            9.0       2021   418.0  186.125000\n",
      "...        ...     ...    ...            ...        ...     ...         ...\n",
      "1040985  497.0  132.75  46.75            9.0       2098  1108.0  221.750000\n",
      "1040986  497.0  132.75  47.25            9.0       2098  1108.0  221.750000\n",
      "1040987  497.0  133.25  45.25            9.0       2098  1108.0    1.845703\n",
      "1040988  497.0  133.25  47.25            9.0       2098  1108.0  221.750000\n",
      "1040989  497.0  137.75  36.75            9.0       2098  1108.0  298.750000\n",
      "\n",
      "[691271 rows x 7 columns]}, 'wheat': {'soil_co2':           year     lon    lat  texture_class  real_year     co2  nitrogen\n",
      "ID                                                                       \n",
      "1319737  420.0 -123.25  44.75            9.0       2021   418.0  102.8125\n",
      "1319738  420.0 -123.25  45.25            9.0       2021   418.0  102.8125\n",
      "1319739  420.0 -123.25  45.75            9.0       2021   418.0  102.8125\n",
      "1319740  420.0 -122.75  44.75            9.0       2021   418.0  102.8125\n",
      "1319741  420.0 -122.75  45.25            9.0       2021   418.0  102.8125\n",
      "...        ...     ...    ...            ...        ...     ...       ...\n",
      "1873717  497.0  152.25 -29.25            9.0       2098  1108.0   40.0625\n",
      "1873718  497.0  152.25 -28.75            9.0       2098  1108.0   40.0625\n",
      "1873719  497.0  152.25 -28.25            9.0       2098  1108.0   40.0625\n",
      "1873720  497.0  152.25 -27.75            9.0       2098  1108.0   40.0625\n",
      "1873721  497.0  152.75 -28.75            9.0       2098  1108.0   40.0625\n",
      "\n",
      "[553878 rows x 7 columns]}}\n",
      "1245149\n"
     ]
    }
   ],
   "source": [
    "print(FEATURES)\n",
    "\n",
    "print(crop_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T11:53:58.986867Z",
     "iopub.status.busy": "2024-12-09T11:53:58.985879Z",
     "iopub.status.idle": "2024-12-09T11:53:59.026551Z",
     "shell.execute_reply": "2024-12-09T11:53:59.025185Z",
     "shell.execute_reply.started": "2024-12-09T11:53:58.986826Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total rows to predict: 1245149\n",
      "     year  count\n",
      "0   420.0   9068\n",
      "1   421.0   9010\n",
      "2   422.0   9047\n",
      "3   423.0   8994\n",
      "4   424.0   9054\n",
      "..    ...    ...\n",
      "73  493.0   8620\n",
      "74  494.0   8847\n",
      "75  495.0   8837\n",
      "76  496.0   8600\n",
      "77  497.0   8773\n",
      "\n",
      "[78 rows x 2 columns]\n",
      "     year  count\n",
      "0   420.0   6871\n",
      "1   421.0   7579\n",
      "2   422.0   6798\n",
      "3   423.0   7346\n",
      "4   424.0   7026\n",
      "..    ...    ...\n",
      "73  493.0   7143\n",
      "74  494.0   7040\n",
      "75  495.0   6929\n",
      "76  496.0   7208\n",
      "77  497.0   7006\n",
      "\n",
      "[78 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of total rows to predict: {len(crop_features_test['wheat']['soil_co2']) + len(crop_features_test['maize']['soil_co2'])}\")\n",
    "\n",
    "yearly_counts_df = pd.DataFrame(crop_features_test['maize']['soil_co2']).groupby('year').size().reset_index(name='count')\n",
    "print(yearly_counts_df)\n",
    "yearly_counts_df = pd.DataFrame(crop_features_test['wheat']['soil_co2']).groupby('year').size().reset_index(name='count')\n",
    "print(yearly_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T11:55:01.620805Z",
     "iopub.status.busy": "2024-12-09T11:55:01.619878Z",
     "iopub.status.idle": "2024-12-09T11:55:01.790608Z",
     "shell.execute_reply": "2024-12-09T11:55:01.789303Z",
     "shell.execute_reply.started": "2024-12-09T11:55:01.620751Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maize: Contain the same values: True\n",
      " 9303, 9303\n",
      "Test maize is a subset of unique lat/lon tuples for maize: True\n",
      "Wheat: Contain the same values: False\n",
      " 8663, 8102\n",
      "Test wheat is a subset of unique lat/lon tuples for wheat: True\n"
     ]
    }
   ],
   "source": [
    "# Merge yield_maize_df with crop_data_train['maize']['soil_co2'] on 'ID' column\n",
    "train_data_maize = pd.merge(yield_maize_df, crop_data_train['maize']['soil_co2'], on='ID')\n",
    "train_data_wheat = pd.merge(yield_wheat_df, crop_data_train['wheat']['soil_co2'], on='ID')\n",
    "\n",
    "test_data_maize = pd.DataFrame(crop_features_test['maize']['soil_co2'])\n",
    "test_data_wheat = pd.DataFrame(crop_features_test['wheat']['soil_co2'])\n",
    "\n",
    "unique_lat_lon_maize = train_data_maize[['lat', 'lon']].drop_duplicates()\n",
    "unique_lat_lon_wheat = train_data_wheat[['lat', 'lon']].drop_duplicates()\n",
    "\n",
    "unique_lat_lon_tuples_maize = list(unique_lat_lon_maize.itertuples(index=False, name=None))\n",
    "unique_lat_lon_tuples_wheat = list(unique_lat_lon_wheat.itertuples(index=False, name=None))\n",
    "\n",
    "#Safety Checks Section\n",
    "test_data_maize = test_data_maize[['lat', 'lon']].drop_duplicates() \n",
    "test_maize = list(test_data_maize.itertuples(index=False, name=None))\n",
    "same_values = set(unique_lat_lon_tuples_maize) == set(test_maize)\n",
    "\n",
    "print(\"Maize: Contain the same values:\", same_values)\n",
    "print(f\" {len(set(unique_lat_lon_tuples_maize))}, {len(set(test_maize))}\")\n",
    "\n",
    "is_subset = set(test_maize).issubset(set(unique_lat_lon_tuples_wheat))\n",
    "print(\"Test maize is a subset of unique lat/lon tuples for maize:\", is_subset)\n",
    "\n",
    "test_data_wheat = test_data_wheat[['lat', 'lon']].drop_duplicates() \n",
    "test_wheat = list(test_data_wheat.itertuples(index=False, name=None))\n",
    "same_values = set(unique_lat_lon_tuples_wheat) == set(test_wheat)\n",
    "\n",
    "print(\"Wheat: Contain the same values:\", same_values)\n",
    "print(f\" {len(set(unique_lat_lon_tuples_wheat))}, {len(set(test_wheat))}\")\n",
    "\n",
    "is_subset = set(test_wheat).issubset(set(unique_lat_lon_tuples_wheat))\n",
    "print(\"Test wheat is a subset of unique lat/lon tuples for wheat:\", is_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T12:05:53.620342Z",
     "iopub.status.busy": "2024-12-09T12:05:53.619928Z",
     "iopub.status.idle": "2024-12-09T12:05:53.627868Z",
     "shell.execute_reply": "2024-12-09T12:05:53.626661Z",
     "shell.execute_reply.started": "2024-12-09T12:05:53.620308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gridcells in training for maize: 9303\n",
      "Number of gridcells in training for wheat: 8663\n",
      "Number of gridcells in test for maize: 9303\n",
      "Number of gridcells in test for wheat: 8102\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of gridcells in training for maize: {len(unique_lat_lon_tuples_maize)}\")\n",
    "print(f\"Number of gridcells in training for wheat: {len(unique_lat_lon_tuples_wheat)}\")\n",
    "\n",
    "print(f\"Number of gridcells in test for maize: {len(test_maize)}\")\n",
    "print(f\"Number of gridcells in test for wheat: {len(test_wheat)}\")\n",
    "\n",
    "def extract_ids(input_set: dict) -> dict:\n",
    "    return (\n",
    "    input_set\n",
    "    .assign(tuple_key=input_set[['lat', 'lon']].apply(tuple, axis=1))\n",
    "    .groupby('tuple_key')\n",
    "    .apply(lambda df: df.index.tolist(), include_groups = False)\n",
    "    .to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T12:21:29.212613Z",
     "iopub.status.busy": "2024-12-09T12:21:29.211623Z",
     "iopub.status.idle": "2024-12-09T12:21:35.015513Z",
     "shell.execute_reply": "2024-12-09T12:21:35.014541Z",
     "shell.execute_reply.started": "2024-12-09T12:21:29.212571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Extracting only IDs of tuples in the Test set\n",
    "#Filtering the train set of wheat\n",
    "\n",
    "# Filter train_data_wheat by checking if the (lat, lon) tuple is in the test set\n",
    "train_data_filtered_wheat = train_data_wheat[train_data_wheat[['lat', 'lon']].apply(tuple, axis=1).isin(test_wheat)]\n",
    "\n",
    "grouped_ids_maize = extract_ids(train_data_maize)\n",
    "\n",
    "grouped_ids_wheat = extract_ids(train_data_filtered_wheat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T12:21:36.980950Z",
     "iopub.status.busy": "2024-12-09T12:21:36.980154Z",
     "iopub.status.idle": "2024-12-09T12:21:36.985971Z",
     "shell.execute_reply": "2024-12-09T12:21:36.984847Z",
     "shell.execute_reply.started": "2024-12-09T12:21:36.980910Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9303\n",
      "8102\n"
     ]
    }
   ],
   "source": [
    "print(len(grouped_ids_maize))\n",
    "print(len(grouped_ids_wheat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T12:59:47.814236Z",
     "iopub.status.busy": "2024-12-09T12:59:47.813341Z",
     "iopub.status.idle": "2024-12-09T12:59:47.821179Z",
     "shell.execute_reply": "2024-12-09T12:59:47.820081Z",
     "shell.execute_reply.started": "2024-12-09T12:59:47.814198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "def computeRegression(input_ids: dict, train_data: dict) -> dict:\n",
    "    # Dictionary to store regression results for each (lat, lon) group\n",
    "    regression_results = {}\n",
    "    \n",
    "    # Iterate over each (lat, lon) group and its associated IDs\n",
    "    for tuple_key, ids in input_ids.items():\n",
    "        # Extract data for the current group\n",
    "        group_data = train_data.loc[ids]\n",
    "        \n",
    "        # Extract 'year' as X and 'yield' as Y\n",
    "        X = group_data['year'].values.reshape(-1, 1)  # Reshape for sklearn\n",
    "        Y = group_data['yield'].values\n",
    "        \n",
    "        # Fit a linear regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, Y)\n",
    "        \n",
    "        # Store the results (coefficients and intercept) for the current group\n",
    "        regression_results[tuple_key] = {\n",
    "            'model': model,\n",
    "            'coefficient': model.coef_[0],  # Slope\n",
    "            'intercept': model.intercept_,  # Intercept\n",
    "        }\n",
    "    \n",
    "    # Display regression results for all groups\n",
    "    for key, result in regression_results.items():\n",
    "        '''\n",
    "        print(f\"Group: {key}\")\n",
    "        print(f\"  Coefficient (Slope): {result['coefficient']}\")\n",
    "        print(f\"  Intercept: {result['intercept']}\")\n",
    "        print()\n",
    "        '''\n",
    "\n",
    "    return regression_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T12:59:51.840043Z",
     "iopub.status.busy": "2024-12-09T12:59:51.839644Z",
     "iopub.status.idle": "2024-12-09T13:00:11.898529Z",
     "shell.execute_reply": "2024-12-09T13:00:11.897678Z",
     "shell.execute_reply.started": "2024-12-09T12:59:51.840007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Computing Regression lines only for tuples (lat,lon) present in the test set, ignoring tuples only in the train set.\n",
    "\n",
    "regression_models_maize = computeRegression(grouped_ids_maize, train_data_maize)\n",
    "regression_models_wheat = computeRegression(grouped_ids_wheat, train_data_wheat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:00:41.852165Z",
     "iopub.status.busy": "2024-12-09T13:00:41.851366Z",
     "iopub.status.idle": "2024-12-09T13:00:50.253265Z",
     "shell.execute_reply": "2024-12-09T13:00:50.252304Z",
     "shell.execute_reply.started": "2024-12-09T13:00:41.852126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ids_to_predict_maize = extract_ids(crop_data_test['maize']['soil_co2'][['year','lat','lon']])\n",
    "ids_to_predict_wheat = extract_ids(crop_data_test['wheat']['soil_co2'][['year','lat','lon']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T12:08:10.792774Z",
     "iopub.status.busy": "2024-12-09T12:08:10.791833Z",
     "iopub.status.idle": "2024-12-09T12:08:10.798105Z",
     "shell.execute_reply": "2024-12-09T12:08:10.797100Z",
     "shell.execute_reply.started": "2024-12-09T12:08:10.792733Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "[351710, 360771, 369753, 378788, 387835, 396867, 405944, 414940, 423861, 432563, 441538, 450480, 459509, 468478, 477399, 486493, 495557, 504546, 513500, 522464, 531276, 539996, 548998, 557976, 566838, 575842, 584700, 593464, 602471, 611330, 620357, 629197, 638208, 646976, 655786, 664694, 673649, 682398, 691114, 699710, 708650, 717580, 726537, 735499, 744380, 753191, 762172, 770935, 779967, 788684, 797561, 806413, 815369, 824055, 833053, 841956, 850745, 859387, 868282, 877142, 885764, 894590, 903154, 912071, 920778, 929205, 937982, 955703, 964403, 973063, 981714, 990364, 999091, 1007899, 1016718, 1025453, 1034119]\n",
      "[1321289, 1328178, 1335778, 1342565, 1349835, 1356901, 1363991, 1370970, 1377782, 1391668, 1398854, 1406247, 1413277, 1420283, 1427536, 1434513, 1441854, 1448980, 1456237, 1463391, 1470745, 1478116, 1485035, 1491997, 1498826, 1506337, 1513439, 1520222, 1527849, 1534624, 1541682, 1549044, 1562888, 1569839, 1577087, 1591219, 1620126, 1627219, 1634318, 1641555, 1648769, 1655933, 1669927, 1677100, 1684257, 1691205, 1698565, 1705799, 1719444, 1726710, 1733979, 1740954, 1748119, 1755121, 1762247, 1769219, 1776380, 1783577, 1790541, 1797762, 1804736, 1811802, 1818705, 1825654, 1832580, 1839846, 1847029, 1861095, 1868335]\n"
     ]
    }
   ],
   "source": [
    "print(len(ids_to_predict_wheat[(-38.75, -60.25)])) #Example of a Subset of IDs\n",
    "print(ids_to_predict_maize[(-38.75, -60.25)])\n",
    "print(ids_to_predict_wheat[(-38.75, -60.25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:00:54.716418Z",
     "iopub.status.busy": "2024-12-09T13:00:54.715651Z",
     "iopub.status.idle": "2024-12-09T13:00:54.734280Z",
     "shell.execute_reply": "2024-12-09T13:00:54.733260Z",
     "shell.execute_reply.started": "2024-12-09T13:00:54.716380Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "result = regression_models_wheat.keys() == ids_to_predict_wheat.keys()\n",
    "print(result)\n",
    "#print(regression_models_wheat.keys())\n",
    "\n",
    "# Find differences\n",
    "missing_in_models = ids_to_predict_wheat.keys() - regression_models_wheat.keys() # Keys in ids_to_predict_wheat but not in regression_models_wheat\n",
    "missing_in_predict = regression_models_wheat.keys() - ids_to_predict_wheat.keys() # Keys in regression_models_wheat but not in ids_to_predict_wheat\n",
    "\n",
    "# Print the differences\n",
    "#print(f\"Keys missing in regression_models_wheat: {missing_in_models}\")\n",
    "#print(f\"Keys missing in ids_to_predict_wheat: {missing_in_predict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:01:07.874986Z",
     "iopub.status.busy": "2024-12-09T13:01:07.874597Z",
     "iopub.status.idle": "2024-12-09T13:01:07.882889Z",
     "shell.execute_reply": "2024-12-09T13:01:07.881849Z",
     "shell.execute_reply.started": "2024-12-09T13:01:07.874953Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generatePredictions(regression_model: dict,\n",
    "                        ids_to_predict: dict, \n",
    "                        X_test: pd.DataFrame) -> dict:\n",
    "    diff_counter = 0\n",
    "\n",
    "    # Dictionary to store future predictions for each (lat, lon) group\n",
    "    future_predictions = {}\n",
    "    \n",
    "    for tuple_key in ids_to_predict.keys():\n",
    "        # Get the model associated to the tuple_key\n",
    "        model = regression_model[tuple_key]['model']\n",
    "        \n",
    "        # Extract the 'lat' and 'lon' from the tuple_key\n",
    "        lat, lon = tuple_key\n",
    "        \n",
    "        # Filter X_test for rows matching the lat and lon\n",
    "        filtered_data = X_test[(X_test['lat'] == lat) & (X_test['lon'] == lon)]\n",
    "        \n",
    "        X_years_to_predict = np.unique(filtered_data['year'].values).reshape(-1,1) #Check the range of years to make prediction\n",
    "        \n",
    "        # Predict yields for the range of future years\n",
    "        predicted_yields = model.predict(X_years_to_predict)\n",
    "        \n",
    "        # Retrieve the list of IDs for this group\n",
    "        ids_for_group = ids_to_predict.get(tuple_key, [])\n",
    "    \n",
    "        # Check if we have enough IDs for the predicted years, some of the tuples of coordinates have one less ID, 76 instead of 77, idk why\n",
    "    \n",
    "        if len(ids_for_group) != len(predicted_yields):\n",
    "            #print(f\"Warning: The number of IDs for {tuple_key} does not match the number of predicted yields.\")\n",
    "            diff_counter+=1\n",
    "    \n",
    "        # Map the predicted yields to the corresponding IDs and store them\n",
    "        future_predictions[tuple_key] = []\n",
    "        for id_, predicted_yield in zip(ids_for_group, predicted_yields):\n",
    "            future_predictions[tuple_key].append({\n",
    "                'id': id_,\n",
    "                'predicted_yield': predicted_yield\n",
    "            })\n",
    "    \n",
    "    print(f\"Warning: The number of retrieved IDs does not match the number of predicted yields {diff_counter} times.\")\n",
    "\n",
    "    return future_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:01:11.484386Z",
     "iopub.status.busy": "2024-12-09T13:01:11.483710Z",
     "iopub.status.idle": "2024-12-09T13:02:33.748177Z",
     "shell.execute_reply": "2024-12-09T13:02:33.747003Z",
     "shell.execute_reply.started": "2024-12-09T13:01:11.484348Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The number of retrieved IDs does not match the number of predicted yields 0 times.\n",
      "Warning: The number of retrieved IDs does not match the number of predicted yields 0 times.\n"
     ]
    }
   ],
   "source": [
    "# Years to Predict: X [420.0, 497.0] (X_unique)\n",
    "# Range of IDs to generate: 1245149 values (wheat + maize)\n",
    "\n",
    "future_predictions_maize = generatePredictions(regression_models_maize, ids_to_predict_maize, crop_data_test['maize']['soil_co2'][['year','lat','lon']])\n",
    "future_predictions_wheat = generatePredictions(regression_models_wheat, ids_to_predict_wheat, crop_data_test['wheat']['soil_co2'][['year','lat','lon']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:11:56.413764Z",
     "iopub.status.busy": "2024-12-09T13:11:56.412709Z",
     "iopub.status.idle": "2024-12-09T13:12:00.327731Z",
     "shell.execute_reply": "2024-12-09T13:12:00.326631Z",
     "shell.execute_reply.started": "2024-12-09T13:11:56.413720Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'predicted_yields.csv' has been saved to /kaggle/working.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prepare the list to store the rows for the DataFrame\n",
    "rows_for_csv = []\n",
    "\n",
    "# Flatten the future_predictions dictionary\n",
    "for tuple_key, predictions in future_predictions_maize.items():\n",
    "    for prediction in predictions:\n",
    "        rows_for_csv.append({\n",
    "            'id': prediction['id'],\n",
    "            'predicted_yield': prediction['predicted_yield']\n",
    "        })\n",
    "\n",
    "for tuple_key, predictions in future_predictions_wheat.items():\n",
    "    for prediction in predictions:\n",
    "        rows_for_csv.append({\n",
    "            'id': prediction['id'],\n",
    "            'predicted_yield': prediction['predicted_yield']\n",
    "        })\n",
    "\n",
    "# Convert the list of rows to a DataFrame\n",
    "df_for_csv = pd.DataFrame(rows_for_csv)\n",
    "df_for_csv_sorted = df_for_csv.sort_values(by='id')\n",
    "\n",
    "# Write to CSV in the Kaggle working directory\n",
    "df_for_csv_sorted.to_csv('/kaggle/working/predicted_yields_linear_regression.csv', index=False)\n",
    "print(\"CSV file 'predicted_yields_linear_regression.csv' has been saved to /kaggle/working.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:11:04.081598Z",
     "iopub.status.busy": "2024-12-09T13:11:04.080891Z",
     "iopub.status.idle": "2024-12-09T13:11:04.091922Z",
     "shell.execute_reply": "2024-12-09T13:11:04.090841Z",
     "shell.execute_reply.started": "2024-12-09T13:11:04.081557Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has 1245149 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577120</th>\n",
       "      <td>349719</td>\n",
       "      <td>4.426638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585874</th>\n",
       "      <td>349720</td>\n",
       "      <td>4.843409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593001</th>\n",
       "      <td>349721</td>\n",
       "      <td>2.897787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568779</th>\n",
       "      <td>349722</td>\n",
       "      <td>1.034766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491417</th>\n",
       "      <td>349723</td>\n",
       "      <td>1.885789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  predicted_yield\n",
       "577120  349719         4.426638\n",
       "585874  349720         4.843409\n",
       "593001  349721         2.897787\n",
       "568779  349722         1.034766\n",
       "491417  349723         1.885789"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rows = len(df_for_csv_sorted)\n",
    "print(f\"The file has {num_rows} rows.\")\n",
    "\n",
    "df_for_csv_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T13:11:51.593321Z",
     "iopub.status.busy": "2024-12-09T13:11:51.592923Z",
     "iopub.status.idle": "2024-12-09T13:11:51.601043Z",
     "shell.execute_reply": "2024-12-09T13:11:51.600123Z",
     "shell.execute_reply.started": "2024-12-09T13:11:51.593286Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Display future predictions (it can crash, printing is sloow)\n",
    "'''\n",
    "for key, predictions in future_predictions.items():\n",
    "    print(f\"Predictions for {key}:\")\n",
    "    for prediction in predictions:\n",
    "        print(f\"ID: {prediction['id']}, Predicted Yield: {prediction['predicted_yield']}\")\n",
    "'''\n",
    "os.remove(\"/kaggle/working/predicted_yields.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8812083,
     "sourceId": 81000,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
