{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d885a439",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-03T20:41:24.824339Z",
     "iopub.status.busy": "2025-01-03T20:41:24.824066Z",
     "iopub.status.idle": "2025-01-03T20:41:25.513465Z",
     "shell.execute_reply": "2025-01-03T20:41:25.512502Z"
    },
    "papermill": {
     "duration": 0.697133,
     "end_time": "2025-01-03T20:41:25.515376",
     "exception": false,
     "start_time": "2025-01-03T20:41:24.818243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/the-future-crop-challenge/pr_wheat_train.parquet\n",
      "/kaggle/input/the-future-crop-challenge/tasmax_maize_train.parquet\n",
      "/kaggle/input/the-future-crop-challenge/sample_submission.csv\n",
      "/kaggle/input/the-future-crop-challenge/soil_co2_wheat_train.parquet\n",
      "/kaggle/input/the-future-crop-challenge/tas_wheat_train.parquet\n",
      "/kaggle/input/the-future-crop-challenge/rsds_maize_train.parquet\n",
      "/kaggle/input/the-future-crop-challenge/tasmin_wheat_train.parquet\n",
      "/kaggle/input/the-future-crop-challenge/tasmax_wheat_train.parquet\n",
      "/kaggle/input/the-future-crop-challenge/rsds_maize_test.parquet\n",
      "/kaggle/input/the-future-crop-challenge/soil_co2_maize_test.parquet\n",
      "/kaggle/input/the-future-crop-challenge/train_solutions_maize.parquet\n",
      "/kaggle/input/the-future-crop-challenge/pr_maize_test.parquet\n",
      "/kaggle/input/the-future-crop-challenge/tas_wheat_test.parquet\n",
      "/kaggle/input/the-future-crop-challenge/tasmax_maize_test.parquet\n",
      "/kaggle/input/the-future-crop-challenge/pr_maize_train.parquet\n",
      "/kaggle/input/the-future-crop-challenge/pr_wheat_test.parquet\n",
      "/kaggle/input/the-future-crop-challenge/soil_co2_maize_train.parquet\n",
      "/kaggle/input/the-future-crop-challenge/tasmin_maize_test.parquet\n",
      "/kaggle/input/the-future-crop-challenge/train_solutions_wheat.parquet\n",
      "/kaggle/input/the-future-crop-challenge/tas_maize_train.parquet\n",
      "/kaggle/input/the-future-crop-challenge/soil_co2_wheat_test.parquet\n",
      "/kaggle/input/the-future-crop-challenge/tasmin_maize_train.parquet\n",
      "/kaggle/input/the-future-crop-challenge/rsds_wheat_test.parquet\n",
      "/kaggle/input/the-future-crop-challenge/tasmin_wheat_test.parquet\n",
      "/kaggle/input/the-future-crop-challenge/tas_maize_test.parquet\n",
      "/kaggle/input/the-future-crop-challenge/tasmax_wheat_test.parquet\n",
      "/kaggle/input/the-future-crop-challenge/rsds_wheat_train.parquet\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import gc\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7a59b",
   "metadata": {
    "papermill": {
     "duration": 0.005256,
     "end_time": "2025-01-03T20:41:25.525254",
     "exception": false,
     "start_time": "2025-01-03T20:41:25.519998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data with reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997534da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:41:25.534948Z",
     "iopub.status.busy": "2025-01-03T20:41:25.534275Z",
     "iopub.status.idle": "2025-01-03T20:41:25.539944Z",
     "shell.execute_reply": "2025-01-03T20:41:25.539221Z"
    },
    "papermill": {
     "duration": 0.012212,
     "end_time": "2025-01-03T20:41:25.541515",
     "exception": false,
     "start_time": "2025-01-03T20:41:25.529303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG_MODE = False\n",
    "\n",
    "CROPS = (\"maize\", \"wheat\")\n",
    "\n",
    "MODES = ('train', 'test')\n",
    "\n",
    "FEATURES_TEMPORAL = {\n",
    "    # Time series data -- 240 columns reflecting daily values for 30 days before sowing and 210 days after.\n",
    "    'tas',       # Mean daily temperature\n",
    "    'tasmax',    # Max daily temperature\n",
    "    'tasmin',    # Min daily temperature\n",
    "    'pr',        # precipitation\n",
    "    'rsds'      # shortwave radiation\n",
    "}\n",
    "\n",
    "FEATURES_STATIC = {\n",
    "    # Static data\n",
    "    'soil_co2',  # crop, year, lon, lat, texture_class, real_year, co2, nitrogen\n",
    "    # dominant USDA soil texture class (constant over time), the ambient CO2 concentration (spatially constant), the planting date and the nitrogen application rate (constant over time)\n",
    "}\n",
    "\n",
    "FEATURES = set.union(FEATURES_TEMPORAL, FEATURES_STATIC)\n",
    "\n",
    "COLUMNS_TO_DROP = ['crop','variable']\n",
    "\n",
    "# Sowing date\n",
    "INDEX_SOW = 30  # days\n",
    "# Time series data length\n",
    "SEASON_LENGTH = 240  # days\n",
    "# Nr. of soil texture classes\n",
    "NUM_TEXTURE_CLASSES = 13  \n",
    "\n",
    "YEAR_TRAIN_MIN = 1982\n",
    "YEAR_TRAIN_MAX = 2020  # Inclusive\n",
    "YEAR_TEST_MIN = 2021\n",
    "YEAR_TEST_MAX = 2098\n",
    "\n",
    "PATH_INPUT = os.path.abspath(os.path.join(os.sep, 'kaggle', 'input', 'the-future-crop-challenge'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8005114",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:41:25.551077Z",
     "iopub.status.busy": "2025-01-03T20:41:25.550463Z",
     "iopub.status.idle": "2025-01-03T20:41:25.559288Z",
     "shell.execute_reply": "2025-01-03T20:41:25.558659Z"
    },
    "papermill": {
     "duration": 0.015119,
     "end_time": "2025-01-03T20:41:25.560741",
     "exception": false,
     "start_time": "2025-01-03T20:41:25.545622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reduce memory usage of a pandas DataFrame\n",
    "def reduce_memory_usage(df):\n",
    "    \"\"\"Reduce memory usage of a pandas DataFrame.\"\"\"\n",
    "    # Function to iterate through columns and modify the data types\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print(f\"Memory usage of dataframe: {start_mem} MB\")\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col in df.index.names:  # Skip index columns, since other formats of index aren't supported by the engine\n",
    "            continue\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)  # Keep sufficient precision\n",
    "            else:\n",
    "                if col == \"year\":  # Ensure precision for grouping columns\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print(f\"Memory usage after optimization: {end_mem} MB\")\n",
    "    #print(f\"Decreased by {100 * (start_mem - end_mem) / start_mem}%\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "607d3b8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:41:25.570150Z",
     "iopub.status.busy": "2025-01-03T20:41:25.569701Z",
     "iopub.status.idle": "2025-01-03T20:41:25.576844Z",
     "shell.execute_reply": "2025-01-03T20:41:25.576028Z"
    },
    "papermill": {
     "duration": 0.013476,
     "end_time": "2025-01-03T20:41:25.578342",
     "exception": false,
     "start_time": "2025-01-03T20:41:25.564866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(crop: str, # Which crop\n",
    "              mode: str, # Which dataset (i.e. train/test)\n",
    "              select_only_features: bool = True, # Drop every other column (crop, year, lon, lat) if not relevant for computation\n",
    "              take_subset: bool = False,  # If set to true, take a small subset of the data (for debugging purposes)\n",
    "             ) -> dict:\n",
    "    assert crop in CROPS\n",
    "    assert mode in MODES\n",
    "    \n",
    "    output = dict()\n",
    "    \n",
    "    for f in FEATURES:\n",
    "        path = os.path.join(PATH_INPUT, f'{f}_{crop}_{mode}.parquet')\n",
    "        df = reduce_memory_usage(pd.read_parquet(path))\n",
    "\n",
    "        columns_to_drop_in_df = [col for col in COLUMNS_TO_DROP if col in df.columns] \n",
    "        if columns_to_drop_in_df:\n",
    "            df = df.drop(columns=columns_to_drop_in_df)\n",
    "\n",
    "        if select_only_features:\n",
    "            if f in FEATURES_TEMPORAL:  # Select only the time series data -- drop other columns\n",
    "                df = df[[str(i) for i in range(SEASON_LENGTH)]]\n",
    "        \n",
    "        output[f] = df\n",
    "\n",
    "        # Free up memory after processing each file\n",
    "        del df  # Explicitly delete the DataFrame\n",
    "        gc.collect()  # Force garbage collection\n",
    "        \n",
    "    if mode == 'train':\n",
    "        output['target'] = pd.read_parquet(os.path.join(PATH_INPUT, f'{mode}_solutions_{crop}.parquet'))\n",
    "    \n",
    "    # If required, only take a subset of the data for debugging purposes -- we don't really care which samples\n",
    "    if take_subset:\n",
    "        num_select = 100  # Take only 100 samples from the dataset\n",
    "        # Select which samples based on the index of some feature\n",
    "        ixs_selected = output[tuple(FEATURES)[0]].index[:num_select]\n",
    "        # Filter all dataframes\n",
    "        output = {\n",
    "            key: df.loc[ixs_selected] for key, df in output.items()\n",
    "        }\n",
    "\n",
    "    '''\n",
    "    for df in output.values():\n",
    "        df.sort_index(inplace=True)\n",
    "    '''\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d10a9214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:41:25.587596Z",
     "iopub.status.busy": "2025-01-03T20:41:25.587328Z",
     "iopub.status.idle": "2025-01-03T20:44:00.806936Z",
     "shell.execute_reply": "2025-01-03T20:44:00.806240Z"
    },
    "papermill": {
     "duration": 155.226683,
     "end_time": "2025-01-03T20:44:00.809128",
     "exception": false,
     "start_time": "2025-01-03T20:41:25.582445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load all available data for all crops\n",
    "crop_data_train = {\n",
    "    crop: load_data(crop, 'train', take_subset=DEBUG_MODE, select_only_features=False) for crop in CROPS\n",
    "}\n",
    "\n",
    "\n",
    "crop_data_test = {\n",
    "    crop: load_data(crop, 'test', take_subset=DEBUG_MODE, select_only_features=False) for crop in CROPS\n",
    "}\n",
    "\n",
    "# Separate data in features and targets (if available)\n",
    "crop_features_train = {\n",
    "    crop: {\n",
    "        k: v for k, v in data.items() if k in FEATURES\n",
    "    } for crop, data in crop_data_train.items()\n",
    "}\n",
    "crop_features_test = {\n",
    "    crop: {\n",
    "        k: v for k, v in data.items() if k in FEATURES\n",
    "    } for crop, data in crop_data_test.items()\n",
    "}\n",
    "\n",
    "crop_targets_train = {\n",
    "    crop: data['target'] for crop, data in crop_data_train.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d31308",
   "metadata": {
    "papermill": {
     "duration": 0.004106,
     "end_time": "2025-01-03T20:44:00.818139",
     "exception": false,
     "start_time": "2025-01-03T20:44:00.814033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extra metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bc9e0cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:44:00.827804Z",
     "iopub.status.busy": "2025-01-03T20:44:00.827519Z",
     "iopub.status.idle": "2025-01-03T20:44:00.834616Z",
     "shell.execute_reply": "2025-01-03T20:44:00.833814Z"
    },
    "papermill": {
     "duration": 0.013953,
     "end_time": "2025-01-03T20:44:00.836269",
     "exception": false,
     "start_time": "2025-01-03T20:44:00.822316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_statistics_on_crop(df):    \n",
    "    #We already have the vars splitte\n",
    "    #Consider relying on tasmax, tasmin instead of these aggregated stats\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean_tas = df['tas'].mean(axis=1).rename('mean_tas')\n",
    "    median_tas = df['tas'].median(axis=1).rename('median_tas')\n",
    "    sum_tas = df['tas'].sum(axis=1).rename('sum_tas')\n",
    "    min_tas = df['tas'].min(axis=1).rename('min_tas')\n",
    "    max_tas = df['tas'].max(axis=1).rename('max_tas')\n",
    "    \n",
    "    mean_pr = df['pr'].mean(axis=1).rename('mean_pr')\n",
    "    median_pr = df['pr'].median(axis=1).rename('median_pr')\n",
    "    sum_pr = df['pr'].sum(axis=1).rename('sum_pr')\n",
    "    min_pr = df['pr'].min(axis=1).rename('min_pr')\n",
    "    max_pr = df['pr'].max(axis=1).rename('max_pr')\n",
    "    \n",
    "    mean_rsds = df['rsds'].mean(axis=1).rename('mean_rsds')\n",
    "    median_rsds = df['rsds'].median(axis=1).rename('median_rsds')\n",
    "    sum_rsds = df['rsds'].sum(axis=1).rename('sum_rsds')\n",
    "    min_rsds = df['rsds'].min(axis=1).rename('min_rsds')\n",
    "    max_rsds = df['rsds'].max(axis=1).rename('max_rsds')\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    summary_df = pd.concat([mean_tas, min_tas, max_tas, median_tas, sum_tas,\n",
    "                            mean_pr, min_pr, max_pr, median_pr, sum_pr,\n",
    "                            mean_rsds, median_rsds, sum_rsds, min_rsds, max_rsds], axis=1)\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe6693b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:44:00.845519Z",
     "iopub.status.busy": "2025-01-03T20:44:00.845296Z",
     "iopub.status.idle": "2025-01-03T20:44:44.929276Z",
     "shell.execute_reply": "2025-01-03T20:44:44.928593Z"
    },
    "papermill": {
     "duration": 44.091039,
     "end_time": "2025-01-03T20:44:44.931417",
     "exception": false,
     "start_time": "2025-01-03T20:44:00.840378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for crop in CROPS:\n",
    "    crop_features_train[crop]['summary'] = reduce_memory_usage(calculate_statistics_on_crop(crop_features_train[crop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f06dd0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:44:44.941279Z",
     "iopub.status.busy": "2025-01-03T20:44:44.940997Z",
     "iopub.status.idle": "2025-01-03T20:44:44.955842Z",
     "shell.execute_reply": "2025-01-03T20:44:44.954767Z"
    },
    "papermill": {
     "duration": 0.021733,
     "end_time": "2025-01-03T20:44:44.957736",
     "exception": false,
     "start_time": "2025-01-03T20:44:44.936003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "          mean_tas  min_tas  max_tas  median_tas  sum_tas   mean_pr  min_pr  \\\n",
      "ID                                                                            \n",
      "1040990   9.289062  -123.25    381.0    8.421875   2258.0  1.245117 -123.25   \n",
      "1040991   8.929688  -123.25    381.0    7.992188   2170.0  1.247070 -123.25   \n",
      "1040992   7.812500  -123.25    381.0    6.933594   1899.0  1.249023 -123.25   \n",
      "1040993   8.726562  -122.75    381.0    7.781250   2122.0  1.247070 -122.75   \n",
      "1040994   9.335938  -122.75    381.0    8.406250   2270.0  1.249023 -122.75   \n",
      "...            ...      ...      ...         ...      ...       ...     ...   \n",
      "1319732  14.609375   -30.25    419.0   11.953125   3550.0  2.226562  -30.25   \n",
      "1319733  15.632812   -29.25    419.0   13.179688   3798.0  2.230469  -29.25   \n",
      "1319734  16.906250   -28.75    419.0   14.257812   4108.0  2.232422  -28.75   \n",
      "1319735  18.906250   -27.75    419.0   16.546875   4592.0  2.236328  -27.75   \n",
      "1319736  19.218750   -28.75    419.0   16.671875   4668.0  2.234375  -28.75   \n",
      "\n",
      "         max_pr  median_pr  sum_pr  mean_rsds  median_rsds      sum_rsds  \\\n",
      "ID                                                                         \n",
      "1040990   381.0   0.000034   302.5    99.6875      77.2500  24225.625000   \n",
      "1040991   381.0   0.000043   303.0    98.2500      77.2500  23878.910156   \n",
      "1040992   381.0   0.000054   303.5    94.4375      74.8750  22953.750000   \n",
      "1040993   381.0   0.000039   303.0   101.3125      76.3750  24621.244141   \n",
      "1040994   381.0   0.000033   303.5    98.7500      74.3125  23990.238281   \n",
      "...         ...        ...     ...        ...          ...           ...   \n",
      "1319732   419.0   0.000000   541.0   185.0000     170.8750  44961.593750   \n",
      "1319733   419.0   0.000000   542.0   186.6250     174.3750  45359.406250   \n",
      "1319734   419.0   0.000000   542.5   187.8750     174.8750  45655.156250   \n",
      "1319735   419.0   0.000000   543.5   185.0000     178.8750  44956.000000   \n",
      "1319736   419.0   0.000000   543.0   181.6250     171.1250  44142.250000   \n",
      "\n",
      "         min_rsds  max_rsds  \n",
      "ID                           \n",
      "1040990   -123.25     381.0  \n",
      "1040991   -123.25     381.0  \n",
      "1040992   -123.25     381.0  \n",
      "1040993   -122.75     381.0  \n",
      "1040994   -122.75     381.0  \n",
      "...           ...       ...  \n",
      "1319732    -30.25     419.0  \n",
      "1319733    -29.25     419.0  \n",
      "1319734    -28.75     419.0  \n",
      "1319735    -27.75     419.0  \n",
      "1319736    -28.75     419.0  \n",
      "\n",
      "[278747 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "print(type(crop_features_train[crop]['summary']))\n",
    "print(crop_features_train[crop]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2051ac10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:44:44.967320Z",
     "iopub.status.busy": "2025-01-03T20:44:44.967056Z",
     "iopub.status.idle": "2025-01-03T20:44:44.971145Z",
     "shell.execute_reply": "2025-01-03T20:44:44.970497Z"
    },
    "papermill": {
     "duration": 0.010358,
     "end_time": "2025-01-03T20:44:44.972643",
     "exception": false,
     "start_time": "2025-01-03T20:44:44.962285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_temp = 10\n",
    "\n",
    "# Function to calculate GDD, heat stress days, and frost days for each group\n",
    "def calculate_metrics(group):\n",
    "    #group['GDD'] = np.maximum(group['mean_tas'] - base_temp, 0).cumsum()\n",
    "    group['heat_stress_days'] = (group['max_tas'] > 30).cumsum()\n",
    "    group['frost_days'] = (group['min_tas'] < 0).cumsum()\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f797af64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:44:44.981786Z",
     "iopub.status.busy": "2025-01-03T20:44:44.981520Z",
     "iopub.status.idle": "2025-01-03T20:44:44.998603Z",
     "shell.execute_reply": "2025-01-03T20:44:44.997742Z"
    },
    "papermill": {
     "duration": 0.023509,
     "end_time": "2025-01-03T20:44:45.000333",
     "exception": false,
     "start_time": "2025-01-03T20:44:44.976824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "1040990    0.0\n",
      "1040991    0.0\n",
      "1040992    0.0\n",
      "1040993    0.0\n",
      "1040994    0.0\n",
      "          ... \n",
      "1319732    inf\n",
      "1319733    inf\n",
      "1319734    inf\n",
      "1319735    inf\n",
      "1319736    inf\n",
      "Name: mean_tas, Length: 278747, dtype: float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: RuntimeWarning: overflow encountered in accumulate\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "g = np.maximum(crop_features_train[crop]['summary']['mean_tas'] - base_temp, 0).cumsum()\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8450ec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:44:45.009936Z",
     "iopub.status.busy": "2025-01-03T20:44:45.009700Z",
     "iopub.status.idle": "2025-01-03T20:44:45.174859Z",
     "shell.execute_reply": "2025-01-03T20:44:45.174102Z"
    },
    "papermill": {
     "duration": 0.172133,
     "end_time": "2025-01-03T20:44:45.176865",
     "exception": false,
     "start_time": "2025-01-03T20:44:45.004732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for crop in CROPS:\n",
    "    crop_features_train[crop]['summary'] = reduce_memory_usage(calculate_metrics(crop_features_train[crop]['summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23654ac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:44:45.187398Z",
     "iopub.status.busy": "2025-01-03T20:44:45.187107Z",
     "iopub.status.idle": "2025-01-03T20:44:45.196403Z",
     "shell.execute_reply": "2025-01-03T20:44:45.195414Z"
    },
    "papermill": {
     "duration": 0.016294,
     "end_time": "2025-01-03T20:44:45.197995",
     "exception": false,
     "start_time": "2025-01-03T20:44:45.181701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         yield\n",
      "ID            \n",
      "1040990  4.775\n",
      "1040991  4.874\n",
      "1040992  4.701\n",
      "1040993  4.848\n",
      "1040994  5.178\n",
      "...        ...\n",
      "1319732  1.418\n",
      "1319733  1.653\n",
      "1319734  1.271\n",
      "1319735  0.469\n",
      "1319736  0.629\n",
      "\n",
      "[278747 rows x 1 columns]\n",
      "        yield\n",
      "ID           \n",
      "0       5.595\n",
      "1       5.895\n",
      "2       3.023\n",
      "3       2.071\n",
      "4       2.239\n",
      "...       ...\n",
      "349714  6.240\n",
      "349715  8.926\n",
      "349716  2.180\n",
      "349717  7.311\n",
      "349718  2.118\n",
      "\n",
      "[349719 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "yield_target_wheat = pd.DataFrame(crop_targets_train['wheat'])\n",
    "print(yield_target_wheat)\n",
    "yield_target_maize = pd.DataFrame(crop_targets_train['maize'])\n",
    "print(yield_target_maize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01215991",
   "metadata": {
    "papermill": {
     "duration": 0.004081,
     "end_time": "2025-01-03T20:44:45.206406",
     "exception": false,
     "start_time": "2025-01-03T20:44:45.202325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LSTM train and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "344bf58f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:44:45.215837Z",
     "iopub.status.busy": "2025-01-03T20:44:45.215535Z",
     "iopub.status.idle": "2025-01-03T20:44:57.503539Z",
     "shell.execute_reply": "2025-01-03T20:44:57.502861Z"
    },
    "papermill": {
     "duration": 12.294822,
     "end_time": "2025-01-03T20:44:57.505468",
     "exception": false,
     "start_time": "2025-01-03T20:44:45.210646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4c9f522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:44:57.516120Z",
     "iopub.status.busy": "2025-01-03T20:44:57.515613Z",
     "iopub.status.idle": "2025-01-03T20:44:57.522423Z",
     "shell.execute_reply": "2025-01-03T20:44:57.521704Z"
    },
    "papermill": {
     "duration": 0.01368,
     "end_time": "2025-01-03T20:44:57.524028",
     "exception": false,
     "start_time": "2025-01-03T20:44:57.510348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_lstm_data(crop_features, crop_targets):\n",
    "    # Préparer les données pour LSTM\n",
    "    X_temporal = []\n",
    "    \n",
    "    # Variables temporelles\n",
    "    temporal_features = ['tas', 'tasmax', 'tasmin', 'pr', 'rsds']\n",
    "    \n",
    "    for feature in temporal_features:\n",
    "        # Convertir les données en numpy array \n",
    "        feat_array = crop_features[feature].values\n",
    "        X_temporal.append(feat_array)\n",
    "    \n",
    "    # Empiler les caractéristiques temporelles\n",
    "    X_temporal = np.stack(X_temporal, axis=-1)\n",
    "    \n",
    "    # Récupérer les données statiques\n",
    "    soil_data = crop_features['soil_co2']\n",
    "    summary = crop_features['summary']\n",
    "    texture_class = soil_data['texture_class'].values.reshape(-1, 1)\n",
    "    co2_level = soil_data['co2'].values.reshape(-1, 1)\n",
    "    heat_level = summary['heat_stress_days'].values.reshape(-1, 1)\n",
    "    frost_level = summary['frost_days'].values.reshape(-1, 1)\n",
    "    \n",
    "    # Normaliser les données statiques\n",
    "    scaler_texture = StandardScaler()\n",
    "    scaler_co2 = StandardScaler()\n",
    "    scaler_heat = StandardScaler()\n",
    "    scaler_frost = StandardScaler() \n",
    "    \n",
    "    texture_scaled = scaler_texture.fit_transform(texture_class)\n",
    "    co2_scaled = scaler_co2.fit_transform(co2_level)\n",
    "    heat_scaled = scaler_co2.fit_transform(heat_level)\n",
    "    frost_scaled = scaler_co2.fit_transform(frost_level)\n",
    "    \n",
    "    # Combiner données statiques et temporelles\n",
    "    X_static = np.hstack([texture_scaled, co2_scaled, heat_scaled, frost_scaled])\n",
    "    \n",
    "    # Préparer les cibles\n",
    "    y = crop_targets['yield'].values\n",
    "    \n",
    "    return X_temporal, X_static, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2d022a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:44:57.533692Z",
     "iopub.status.busy": "2025-01-03T20:44:57.533413Z",
     "iopub.status.idle": "2025-01-03T20:44:57.537949Z",
     "shell.execute_reply": "2025-01-03T20:44:57.537209Z"
    },
    "papermill": {
     "duration": 0.011184,
     "end_time": "2025-01-03T20:44:57.539460",
     "exception": false,
     "start_time": "2025-01-03T20:44:57.528276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape_temporal, input_shape_static):\n",
    "    model = Sequential([\n",
    "        # Couche LSTM pour les données temporelles\n",
    "        LSTM(64, input_shape=input_shape_temporal, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Couche pour intégrer les données statiques\n",
    "        Dense(16, activation='relu'),\n",
    "        \n",
    "        # Couche de sortie\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tfk.optimizers.Adam(1e-3)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bd2e630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T20:44:57.549083Z",
     "iopub.status.busy": "2025-01-03T20:44:57.548859Z",
     "iopub.status.idle": "2025-01-03T22:15:16.790416Z",
     "shell.execute_reply": "2025-01-03T22:15:16.789354Z"
    },
    "papermill": {
     "duration": 5422.863572,
     "end_time": "2025-01-03T22:15:20.407351",
     "exception": false,
     "start_time": "2025-01-03T20:44:57.543779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 25ms/step - loss: 1.8761 - mae: 0.9938 - val_loss: 1.1174 - val_mae: 0.7908 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 1.1590 - mae: 0.8036 - val_loss: 1.0475 - val_mae: 0.7624 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 1.0763 - mae: 0.7736 - val_loss: 0.9830 - val_mae: 0.7323 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 1.0191 - mae: 0.7516 - val_loss: 1.0085 - val_mae: 0.7340 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.9815 - mae: 0.7352 - val_loss: 0.9696 - val_mae: 0.7298 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.9566 - mae: 0.7249 - val_loss: 0.9211 - val_mae: 0.7160 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.9248 - mae: 0.7119 - val_loss: 0.9231 - val_mae: 0.7068 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.9064 - mae: 0.7048 - val_loss: 0.8693 - val_mae: 0.6911 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.8852 - mae: 0.6973 - val_loss: 0.8783 - val_mae: 0.6941 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.8731 - mae: 0.6909 - val_loss: 0.8645 - val_mae: 0.6881 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.8653 - mae: 0.6885 - val_loss: 0.8372 - val_mae: 0.6737 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 25ms/step - loss: 0.8420 - mae: 0.6784 - val_loss: 0.8207 - val_mae: 0.6678 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 25ms/step - loss: 0.8396 - mae: 0.6770 - val_loss: 0.8813 - val_mae: 0.6890 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.8267 - mae: 0.6698 - val_loss: 0.8196 - val_mae: 0.6691 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.8201 - mae: 0.6690 - val_loss: 0.8021 - val_mae: 0.6624 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.8031 - mae: 0.6611 - val_loss: 0.8639 - val_mae: 0.6778 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.7955 - mae: 0.6580 - val_loss: 0.8173 - val_mae: 0.6578 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.7930 - mae: 0.6582 - val_loss: 0.8041 - val_mae: 0.6591 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.7364 - mae: 0.6336 - val_loss: 0.7483 - val_mae: 0.6383 - learning_rate: 1.0000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.7225 - mae: 0.6253 - val_loss: 0.7464 - val_mae: 0.6386 - learning_rate: 1.0000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.7076 - mae: 0.6204 - val_loss: 0.7337 - val_mae: 0.6303 - learning_rate: 1.0000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.7001 - mae: 0.6183 - val_loss: 0.7368 - val_mae: 0.6299 - learning_rate: 1.0000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.7047 - mae: 0.6194 - val_loss: 0.7277 - val_mae: 0.6263 - learning_rate: 1.0000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.7052 - mae: 0.6182 - val_loss: 0.7316 - val_mae: 0.6287 - learning_rate: 1.0000e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.6986 - mae: 0.6161 - val_loss: 0.7213 - val_mae: 0.6230 - learning_rate: 1.0000e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 25ms/step - loss: 0.6934 - mae: 0.6139 - val_loss: 0.7251 - val_mae: 0.6270 - learning_rate: 1.0000e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.6922 - mae: 0.6138 - val_loss: 0.7289 - val_mae: 0.6274 - learning_rate: 1.0000e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.6909 - mae: 0.6132 - val_loss: 0.7317 - val_mae: 0.6301 - learning_rate: 1.0000e-04\n",
      "Epoch 29/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 25ms/step - loss: 0.6812 - mae: 0.6094 - val_loss: 0.7259 - val_mae: 0.6268 - learning_rate: 1.0000e-05\n",
      "Epoch 30/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 25ms/step - loss: 0.6807 - mae: 0.6084 - val_loss: 0.7259 - val_mae: 0.6262 - learning_rate: 1.0000e-05\n",
      "Epoch 31/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 25ms/step - loss: 0.6819 - mae: 0.6088 - val_loss: 0.7249 - val_mae: 0.6254 - learning_rate: 1.0000e-05\n",
      "Epoch 32/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.6787 - mae: 0.6069 - val_loss: 0.7238 - val_mae: 0.6257 - learning_rate: 1.0000e-05\n",
      "Epoch 33/80\n",
      "\u001b[1m3485/3485\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - loss: 0.6822 - mae: 0.6099 - val_loss: 0.7223 - val_mae: 0.6248 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 25ms/step - loss: 3.5888 - mae: 1.3480 - val_loss: 2.4334 - val_mae: 1.0869 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 24ms/step - loss: 2.4609 - mae: 1.0984 - val_loss: 2.2201 - val_mae: 1.0338 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 24ms/step - loss: 2.2844 - mae: 1.0536 - val_loss: 2.0637 - val_mae: 0.9909 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 24ms/step - loss: 2.1511 - mae: 1.0202 - val_loss: 2.0024 - val_mae: 0.9789 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 2.0367 - mae: 0.9949 - val_loss: 1.9551 - val_mae: 0.9709 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.9672 - mae: 0.9795 - val_loss: 1.8861 - val_mae: 0.9528 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.9117 - mae: 0.9638 - val_loss: 1.9513 - val_mae: 0.9570 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.8429 - mae: 0.9468 - val_loss: 1.8219 - val_mae: 0.9255 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.7987 - mae: 0.9348 - val_loss: 1.7657 - val_mae: 0.9144 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.7546 - mae: 0.9238 - val_loss: 1.8727 - val_mae: 0.9495 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.7220 - mae: 0.9149 - val_loss: 1.7291 - val_mae: 0.9031 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.6752 - mae: 0.9028 - val_loss: 1.6809 - val_mae: 0.8981 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.6646 - mae: 0.9004 - val_loss: 1.6972 - val_mae: 0.8932 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.6466 - mae: 0.8943 - val_loss: 1.8234 - val_mae: 0.9163 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.6101 - mae: 0.8850 - val_loss: 1.6813 - val_mae: 0.8898 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 24ms/step - loss: 1.4775 - mae: 0.8456 - val_loss: 1.4934 - val_mae: 0.8400 - learning_rate: 1.0000e-04\n",
      "Epoch 17/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.4317 - mae: 0.8329 - val_loss: 1.5307 - val_mae: 0.8502 - learning_rate: 1.0000e-04\n",
      "Epoch 18/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.4198 - mae: 0.8294 - val_loss: 1.5933 - val_mae: 0.8625 - learning_rate: 1.0000e-04\n",
      "Epoch 19/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.4221 - mae: 0.8281 - val_loss: 1.5265 - val_mae: 0.8430 - learning_rate: 1.0000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 25ms/step - loss: 1.3946 - mae: 0.8225 - val_loss: 1.5282 - val_mae: 0.8461 - learning_rate: 1.0000e-05\n",
      "Epoch 21/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.3810 - mae: 0.8182 - val_loss: 1.5241 - val_mae: 0.8453 - learning_rate: 1.0000e-05\n",
      "Epoch 22/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.3844 - mae: 0.8175 - val_loss: 1.5204 - val_mae: 0.8442 - learning_rate: 1.0000e-05\n",
      "Epoch 23/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.3798 - mae: 0.8182 - val_loss: 1.5270 - val_mae: 0.8456 - learning_rate: 1.0000e-05\n",
      "Epoch 24/80\n",
      "\u001b[1m4372/4372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 25ms/step - loss: 1.3867 - mae: 0.8189 - val_loss: 1.5314 - val_mae: 0.8469 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Préparation des données pour chaque culture\n",
    "crops = ['wheat', 'maize']\n",
    "models = {}\n",
    "\n",
    "for crop in crops:\n",
    "    # Charger les données\n",
    "    X_temporal, X_static, y = prepare_lstm_data(\n",
    "        crop_features_train[crop], \n",
    "        crop_targets_train[crop]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Diviser les données en train et validation\n",
    "    X_temporal_train, X_temporal_val, X_static_train, X_static_val, y_train, y_val = train_test_split(\n",
    "        X_temporal, X_static, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Créer et entraîner le modèle\n",
    "    model = create_lstm_model(\n",
    "        input_shape_temporal=(X_temporal_train.shape[1], X_temporal_train.shape[2]),\n",
    "        input_shape_static=X_static_train.shape[1]\n",
    "    )\n",
    "\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',   # Surveille la perte sur le set de validation\n",
    "        patience=8,          # Arrête si aucune amélioration après 10 époques\n",
    "        restore_best_weights=True  # Restaure les poids avec la meilleure val_loss\n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=3,\n",
    "        min_lr=1e-5\n",
    "    )\n",
    "\n",
    "    callbacks = [early_stopping, reduce_lr]\n",
    "    \n",
    "    # Entraînement\n",
    "    history = model.fit(\n",
    "        [X_temporal_train, X_static_train], \n",
    "        y_train,\n",
    "        validation_data=([X_temporal_val, X_static_val], y_val),\n",
    "        epochs=80, \n",
    "        batch_size=64, \n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Sauvegarder le modèle\n",
    "    models[crop] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de4d4e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:15:27.963785Z",
     "iopub.status.busy": "2025-01-03T22:15:27.963421Z",
     "iopub.status.idle": "2025-01-03T22:15:27.967340Z",
     "shell.execute_reply": "2025-01-03T22:15:27.966539Z"
    },
    "papermill": {
     "duration": 3.837436,
     "end_time": "2025-01-03T22:15:27.969015",
     "exception": false,
     "start_time": "2025-01-03T22:15:24.131579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # NO VALIDATION\n",
    "# Préparation des données pour chaque culture\n",
    "# crops = ['wheat', 'maize']\n",
    "\n",
    "# for crop in crops:\n",
    "#     # Charger les données\n",
    "#     X_temporal_test, X_static_test, y_test = prepare_lstm_data(\n",
    "#         crop_features_test[crop], \n",
    "#         crop_targets_test[crop]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d299632c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:15:35.628531Z",
     "iopub.status.busy": "2025-01-03T22:15:35.628179Z",
     "iopub.status.idle": "2025-01-03T22:15:35.632327Z",
     "shell.execute_reply": "2025-01-03T22:15:35.631490Z"
    },
    "papermill": {
     "duration": 3.851471,
     "end_time": "2025-01-03T22:15:35.633948",
     "exception": false,
     "start_time": "2025-01-03T22:15:31.782477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Évaluation des modèles\n",
    "# for crop, model in models.items():\n",
    "#     print(f\"Évaluation du modèle pour {crop}:\")\n",
    "#     loss, mae = model.evaluate(\n",
    "#         [X_temporal_test, X_static_test], \n",
    "#         y_test\n",
    "#     )\n",
    "#     print(f\"Loss: {loss}, MAE: {mae}\")\n",
    "    \n",
    "#     model_filename = f\"model_{crop}.keras\"\n",
    "#     model.save(model_filename)\n",
    "#     print(f\"Model saved to {model_filename}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723f2988",
   "metadata": {
    "papermill": {
     "duration": 3.851746,
     "end_time": "2025-01-03T22:15:43.112755",
     "exception": false,
     "start_time": "2025-01-03T22:15:39.261009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e47dc9b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:15:50.621368Z",
     "iopub.status.busy": "2025-01-03T22:15:50.621028Z",
     "iopub.status.idle": "2025-01-03T22:15:50.625568Z",
     "shell.execute_reply": "2025-01-03T22:15:50.624769Z"
    },
    "papermill": {
     "duration": 3.775807,
     "end_time": "2025-01-03T22:15:50.627501",
     "exception": false,
     "start_time": "2025-01-03T22:15:46.851694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sequential name=sequential, built=True>\n",
      "<Sequential name=sequential_1, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(models['wheat'])\n",
    "print(models['maize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "422f6a58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T22:15:58.035756Z",
     "iopub.status.busy": "2025-01-03T22:15:58.035147Z",
     "iopub.status.idle": "2025-01-03T22:23:23.539401Z",
     "shell.execute_reply": "2025-01-03T22:23:23.538377Z"
    },
    "papermill": {
     "duration": 449.193811,
     "end_time": "2025-01-03T22:23:23.541236",
     "exception": false,
     "start_time": "2025-01-03T22:15:54.347425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions pour la culture : wheat\n",
      "\u001b[1m17309/17309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7ms/step\n",
      "Prédictions pour la culture : maize\n",
      "\u001b[1m21603/21603\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 7ms/step\n",
      "Fichier de soumission généré : submission.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "submission = []\n",
    "\n",
    "# Itérer sur chaque culture (maize, wheat)\n",
    "for crop in crops:\n",
    "    print(f\"Prédictions pour la culture : {crop}\")\n",
    "    \n",
    "    # Accéder aux données de test pour la culture\n",
    "    features = crop_features_test[crop]\n",
    "\n",
    "    features['summary'] = reduce_memory_usage(calculate_statistics_on_crop(features))\n",
    "    features['summary'] = reduce_memory_usage(calculate_metrics(features['summary']))\n",
    "    \n",
    "    \n",
    "    # Préparer les données avec la fonction `prepare_lstm_data` pour obtenir X_temporal, X_static et y (même si on ne l'utilise pas ici)\n",
    "    X_temporal, X_static, _ = prepare_lstm_data(features, crop_targets_train[crop]) \n",
    "    \n",
    "    \n",
    "    # Charger le modèle pour la culture\n",
    "    model = models[crop]\n",
    "    \n",
    "    # Faire les prédictions\n",
    "    yield_predictions = model.predict([X_temporal, X_static]).flatten()\n",
    "    \n",
    "    # Récupérer les IDs pour la culture\n",
    "    IDs = features['soil_co2'].index.values  # Les IDs viennent des index des données\n",
    "    \n",
    "    # Créer un DataFrame pour la culture\n",
    "    crop_submission = pd.DataFrame({\n",
    "        'ID': IDs,\n",
    "        'yield': yield_predictions\n",
    "    })\n",
    "    \n",
    "    # Ajouter au fichier final\n",
    "    submission.append(crop_submission)\n",
    "\n",
    "# Combiner toutes les prédictions\n",
    "submission_df = pd.concat(submission)\n",
    "\n",
    "# Sauvegarder dans un fichier CSV\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Fichier de soumission généré : submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb17c4",
   "metadata": {
    "papermill": {
     "duration": 4.143651,
     "end_time": "2025-01-03T22:23:31.680155",
     "exception": false,
     "start_time": "2025-01-03T22:23:27.536504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8812083,
     "sourceId": 81000,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6137.313518,
   "end_time": "2025-01-03T22:23:39.753937",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-03T20:41:22.440419",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
